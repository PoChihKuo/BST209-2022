---
title: 'Basic Data Wrangling'
output: html_document
---

Up to now we have been changing vectors by reordering them and subsetting them through indexing. But once we start more advanced analyses, we will want to prepare data tables for data analysis. We refer to this task as data wrangling. 
For this purpose we will introduce the `dplyr` package which provides intuitive functionality for working with tables. 

Once you install `dplyr` you can load it using 

```{r, warning=FALSE, message=FALSE}
library(dplyr)
```

This package introduces functions that perform the most common operations in data warngling and uses names for these functions that are relatively easy to remember. For example, to change the data table by adding a new column, we use `mutate`. To filter the data table to a subset of rows we use `filter` and to subset the data by selecting specific columns we use `select`. We can also perform a series of operations. For example, select and then filter, by sending the results of one function to another using what is called the _pipe operator_: `%>%`. Some details are included below. 

### Adding a column with `mutate`

We want all the necessary information for our analysis to be included in the data table. So the first task is to add the murder rate to our data frame. The function mutate takes the data frame as a first argument and the name and values of the variable in the second using the convention `name = values`. So to add murder rate we use:
 
```{r,message=FALSE}
library(dslabs)
data(murders)

murders <- mutate(murders, murder_rate = total / population * 100000)
```

Note that here we used `total` and `population` in the function, which are objects that are **not** defined in our workspace. What is happening is that `mutate` knows to look for these variables in the `murders` data frame because the first argument we put was the `murders` data frame. So the intuitive line of code above does exactly what we want. We can see the new column is added:

```{r}
head(murders)
```

Also note that we have over-written the original `murders` object. However, this does *not* change the object that is saved and loaded with `data(murders)`. If we load the `murders` data again, the original will over-write our mutated version.

Note: If we reload the dataset from the `dslabs` package it will rewrite our new data frame with the original.

### Subsetting with `filter`

Now suppose that we want to filter the data table to only show the entries for which the murder rate is lower than 0.71. To do this we use the `filter` function which takes the data table as an argument and then the conditional statement as the next argument. Like mutate, we can use the data table variable names inside the function and it will know we mean the columns and not objects in the workspace.

```{r}
filter(murders, murder_rate <= 0.71)
```


### Selecting columns with `select`

Although our data table only has six columns, some data tables include hundreds. If we want to view just a few, we can use the `select` function. In the code below we select three columns, assign this to a new object and then filter the new object: 

```{r}
new_table <- select(murders, state, region, murder_rate)
filter(new_table, murder_rate <= 0.71)
```

Note that in the call to `select`, the first argument, `murders`, is an object but `state`, `region`, and `murder_rate` are variable names. 

### The pipe: `%>%`

In the code above we wanted to show the three variables for states that have murder rates below 0.71. To do this we defined an intermediate object. In `dplyr` we can write code that looks more like our description of what we want to: 

>> original data $\rightarrow$ select $\rightarrow$ filter

For such an operation, we can use the pipe `%>%`. The code looks like this:

```{r}
murders %>% select(state, region, murder_rate) %>% filter(murder_rate <= 0.71)
```

This line of code is equivalent to the two lines of code above. Note that when using the pipe we no longer need to specify the murders data frame since the `dplyr` functions assume that whatever is being _piped_ is what should be operated on.

## Summarizing data with `dplyr`

An important part of exploratory data analysis is summarizing data. It is sometimes useful to split data into groups before summarizing. 

### Summarize

The `summarize` function in `dplyr` provides a way to compute summary statistics with intuitive and readable code. We can compute the average of the murder rates like this.


```{r}
murders %>% summarize(avg = mean(murder_rate))
```

However, note that the US murder rate is **not** the average of the state murder rates. Because in this computation the small states are given the same weight as the large ones. The US murder rate is proportional to the total US murders divided by the total US population.

To compute the country's average murder rate using the `summarize` function, we can do the following: 

```{r}
us_murder_rate <- murders %>% 
  summarize(murder_rate = sum(total) / sum(population) * 100000)

us_murder_rate
```


This computation counts larger states proportionally to their size and this results in a larger value.

### Using the dot to access the piped data 

The `us_murder_rate` object defined above represents just one number. Yet we are storing it in a data frame

```{r}
class(us_murder_rate)
```

since, as with most `dplyr` functions, `summarize` *always returns a data frame*.

This might be problematic if we want to use the result with functions that require a numeric value. Here we show a useful trick to access values stored in data piped via `%>%`: when a data object is piped it can be accessed using the dot `.`. To understand what we mean take a look at this line of code:

```{r}
us_murder_rate %>% .$murder_rate
```

Note that this returns the value in the `murder_rate` column of `us_murder_rate` making it equivalent to `us_murder_rate$murder_rate`. To understand this line, you just need to think of `.` as a placeholder for the data that is being passed through the pipe. Because this data object is a data frame, we can access it's columns with the `$`. 

To get a number from the original data table with one line of code we can type:

```{r}
us_murder_rate <- murders %>% 
  summarize( murder_rate = sum(total) / sum(population) * 100000) %>%
  .$murder_rate

us_murder_rate
```

which is now a numeric:

```{r}
class(us_murder_rate)
```

We will see other instances in which using the `.` is useful. For now, we will only use it to produce numeric vectors from pipelines constructed with `dplyr`.

### Group then summarize

A common operation in data exploration is to first split data into groups and then compute summaries for each group. For example, we may want to compute the median murder rate for each region. The `group_by` function helps us do this. 

If we type this:

```{r}
murders %>% 
  group_by(region) %>%
  summarize(median_rate = median(murder_rate),
            mean_rate = mean(murder_rate))
```

we get a table with the median murde rate for each of the four regions.

### Sorting data tables

When examining a dataset it is often convenient to sort the table by the different columns. We know about the `order` and `sort` functions, but for ordering entire tables, the `dplyr` function `arrange` is useful. For example, here we order the states by population size:

```{r}
murders %>% 
  arrange(population) %>% 
  head()
```

Note that we get to decide which column to sort by. To see the states by murder rate, from smallest to largest, we arrange by `murder_rate` instead:

```{r}
murders %>% 
  arrange(murder_rate) %>% 
  head()
```

Note that the default behavior is to order in ascending order. In `dplyr`, the function `desc` transforms a vector to be in descending order. So if we want to sort the table in descending order we can type

```{r}
murders %>% 
  arrange(desc(murder_rate)) %>% 
  head()
```

#### Nested Sorting

If we are ordering by a column with ties we can use a second column to break the tie. Similarly, a third column can be used to break ties between the first and second and so on. Here we order by `region` then within region we order by murder rate:

```{r}
murders %>% 
  arrange(region, murder_rate) %>% 
  head()
```


## Basic plots

Exploratory data visualization is perhaps the strength of R. One can quickly go from idea to data to plot with a unique balance of flexibility and ease. For example, Excel may be easier than R but it is no where near as flexible. D3 may be more flexible and powerful than R, but it takes much longer to generate a plot. The next section is dedicated to this topic, but here we introduce some very basic plotting functions.

### Scatter plots

Earlier we inferred that states with larger populations are likely to have more murders. This can be confirmed with an exploratory visualization that plots these two quantities against each other:

```{r, first-plot}
population_in_millions <- murders$population/10^6
total_gun_murders <- murders$total
plot(population_in_millions, total_gun_murders)
```

We can clearly see a relationship.
**Advanced**: For a quick plot that avoids accessing variables twice, we can use the `with` function
```{r, eval=FALSE}
with(murders, plot(population, total))
```


### Histograms

We will describe histograms as they relate to distributions in the next section. Here we will simply note that histograms are a powerful graphical summary of a list of numbers that gives you a general overview of the types of values you have. We can make a histogram of our murder rates by simply typing

```{r, warning=FALSE, message=FALSE}
murders <- mutate(murders, murder_rate = total / population * 100000)
hist(murders$murder_rate)
```

We can see that there is a wide range of values with most of them between 2 and 3 and one very extreme case with a murder rate of more than 15:

```{r}
murders$state[which.max(murders$murder_rate)]
```

### Boxplot

Boxplots will be described in more detail in the next section as well. But here we say that they provide a more terse summary than the histogram - but they are easier to stack with other boxplots. Here we can use them to compare the different regions.

```{r}
boxplot(murder_rate~region, data = murders)
```

We can see that the South has larger murder rates than the other three regions.
